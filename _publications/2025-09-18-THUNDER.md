---
layout: page
title:  "THUNDER: Tile-level Histopathology image UNDERstanding benchmark"
date:   2025-09-18 00:00:00 +0100
categories: [Computational Pathology]
tags: paper
image: /assets/img/thunder_teaser.png
short_desc: A tile-level histopathology image understanding benchmark
published_at: NeurIPS 2025 Datasets and Benchmarks Track
---

Pierre Marza, Leo Fillioux, Sofi√®ne Boutaj, Kunal Mahatha, Christian Desrosiers, Pablo Piantanida, Jose Dolz, Stergios Christodoulidis, Maria Vakalopoulou

*NeurIPS 2025 Datasets and Benchmarks Track **(Spotlight)***

[[arxiv](https://arxiv.org/abs/2507.07860){:target="_blank"}] [[code](https://github.com/MICS-Lab/thunder){:target="_blank"}] [[docs](https://mics-lab.github.io/thunder/){:target="_blank"}]

<div class="row">
    <div class="mx-auto w-75 pb-5">
        <img src="/assets/img/thunder_overall.png" alt="natmed23" width="100%"/>
    </div>
</div>

**Abstract:** Progress in a research field can be hard to assess, in particular when many concurrent methods are proposed in a short period of time. This is the case in digital pathology, where many foundation models have been released recently to serve as feature extractors for tile-level images, being used in a variety of downstream tasks, both for tile- and slide-level problems. Benchmarking available methods then becomes paramount to get a clearer view of the research landscape. In particular, in critical domains such as healthcare, a benchmark should not only focus on evaluating downstream performance, but also provide insights about the main differences between methods, and importantly, further consider uncertainty and robustness to ensure a reliable usage of proposed models. For these reasons, we introduce THUNDER, a tile-level benchmark for digital pathology foundation models, allowing for efficient comparison of many models on diverse datasets with a series of downstream tasks, studying their feature spaces and assessing the robustness and uncertainty of predictions informed by their embeddings. THUNDER is a fast, easy-to-use, dynamic benchmark that can already support a large variety of state-of-the-art foundation, as well as local user-defined models for direct tile-based comparison. In this paper, we provide a comprehensive comparison of 23 foundation models on 16 different datasets covering diverse tasks, feature analysis, and robustness.

<pre>
@article{marza2025thunder,
  title={THUNDER: Tile-level Histopathology image UNDERstanding benchmark},
  author={Marza, Pierre and Fillioux, Leo and Boutaj, Sofi{\`e}ne and Mahatha, Kunal and Desrosiers, Christian and Piantanida, Pablo and Dolz, Jose and Christodoulidis, Stergios and Vakalopoulou, Maria},
  journal={Neural Information Processing Systems (NeurIPS) D&B Track},
  year={2025}
}
</pre>